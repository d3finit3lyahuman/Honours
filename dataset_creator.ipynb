{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"mrjunos/depression-reddit-cleaned\")\n",
    "train = ds[\"train\"]\n",
    "\n",
    "df = pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we understand that most people who reply immed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to r depression s check in post a plac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone else instead of sleeping more when depr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ve kind of stuffed around a lot in my life d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep is my greatest and most comforting escap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  we understand that most people who reply immed...      1\n",
       "1  welcome to r depression s check in post a plac...      1\n",
       "2  anyone else instead of sleeping more when depr...      1\n",
       "3  i ve kind of stuffed around a lot in my life d...      1\n",
       "4  sleep is my greatest and most comforting escap...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lol what anna schmance i soo wan na meet up wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have a tendency to ob over some thing that h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im tired i m so tired a tiredness that i can t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>katyrullman this is why you need to not be ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watchin i m not there and missing heath ledger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  lol what anna schmance i soo wan na meet up wi...      0\n",
       "1  i have a tendency to ob over some thing that h...      1\n",
       "2  im tired i m so tired a tiredness that i can t...      1\n",
       "3  katyrullman this is why you need to not be ove...      0\n",
       "4     watchin i m not there and missing heath ledger      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "gemini_client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "openrouter_client = OpenAI(base_url=\"https://openrouter.ai/api/v1\",api_key=os.getenv(\"OPENROUTER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = gemini_client.models.generate_content(\n",
    "#     model=\"gemini-2.0-flash\",\n",
    "#     contents=\"Explain the concept of a blockchain.\",\n",
    "# )\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt template\n",
    "def generate_prompt(input_text):\n",
    "    return f\"\"\"\n",
    "    You are a highly intelligent mental health professional tasked with identifying whether a given text exert from an individual shows signs of depression.\n",
    " You must use likert scale to rate the severity of the depression. The ranges are 0 to 4 with 0 being no depression, 1 being mild depression, 2 being moderate depression, 3 being severe depression, and 4 being extreme depression. You must also provide a brief explanation of why you rated the individual as such. \n",
    "Input:\n",
    "{input_text}\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the function to call the OpenAI API\n",
    "def get_depression_severity(df,model=\"gemini-2.0-flash\",num_samples=df.shape[0]):\n",
    "    \"\"\"\n",
    "    Process texts from dataframe and get depression severity ratings from Gemini\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing text data\n",
    "        num_samples: Number of samples to process (default 5 to avoid excessive API calls)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with original data, severity ratings and explanations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    result_df = df.head(num_samples).copy()\n",
    "    result_df['severity_rating'] = None\n",
    "    result_df['explanation'] = None\n",
    "    \n",
    "    for idx, row in tqdm(result_df.iterrows(), total=len(result_df), desc=\"Processing samples\"):\n",
    "        text = row['text']\n",
    "        prompt = generate_prompt(text)\n",
    "        \n",
    "        # Count words and characters\n",
    "        # num_words = len(str(text).split())\n",
    "        # num_characters = len(str(text))\n",
    "        # print(f\"Sample {idx}: {num_words} words and {num_characters} characters\")\n",
    "        \n",
    "        try:\n",
    "            response = gemini_client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=prompt,\n",
    "                # config=types.GenerationConfig(\n",
    "                #     system_instructions=\"You are a highly intelligent mental health professional tasked with identifying whether a given text exert from an individual shows signs of depression.\"\n",
    "                # )\n",
    "            )\n",
    "            result = response.text\n",
    "            \n",
    "            # Try to extract rating and explanation\n",
    "            try:\n",
    "                # Assuming the response is formatted with a numerical rating followed by explanation\n",
    "                lines = result.strip().split('\\n')\n",
    "                rating_text = next((line for line in lines if any(str(i) in line for i in range(5))), '')\n",
    "                rating = next((int(i) for i in range(5) if str(i) in rating_text), None)\n",
    "                \n",
    "                # Get explanation (everything after the rating)\n",
    "                explanation = '\\n'.join(lines[lines.index(rating_text) + 1:]) if rating_text in lines else result\n",
    "                \n",
    "                result_df.at[idx, 'severity_rating'] = rating\n",
    "                result_df.at[idx, 'explanation'] = explanation.strip()\n",
    "            except:\n",
    "                # If parsing fails, store the full response in explanation\n",
    "                result_df.at[idx, 'severity_rating'] = None\n",
    "                result_df.at[idx, 'explanation'] = result\n",
    "                \n",
    "            if num_samples > 20:\n",
    "                time.sleep(3)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {idx}: {e}\")\n",
    "            result_df.at[idx, 'severity_rating'] = None\n",
    "            result_df.at[idx, 'explanation'] = f\"Error: {str(e)}\"\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function as above but with openrouter\n",
    "def get_depression_severity_openrouter(df, model, num_samples=df.shape[0]):\n",
    "    \"\"\"\n",
    "    Process texts from dataframe and get depression severity ratings from OpenAI\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing text data\n",
    "        num_samples: Number of samples to process (default 5 to avoid excessive API calls)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with original data, severity ratings and explanations\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    result_df = df.head(num_samples).copy()\n",
    "    result_df['severity_rating'] = None\n",
    "    result_df['explanation'] = None\n",
    "\n",
    "    if model is None:\n",
    "        raise ValueError(\"Model name must be provided.\")\n",
    "    \n",
    "    for idx, row in tqdm(result_df.iterrows(), total=len(result_df), desc=\"Processing samples\"):\n",
    "        text = row['text']\n",
    "        prompt = generate_prompt(text)\n",
    "        \n",
    "        # Count words and characters\n",
    "        # num_words = len(str(text).split())\n",
    "        # num_characters = len(str(text))\n",
    "        # print(f\"Sample {idx}: {num_words} words and {num_characters} characters\")\n",
    "        \n",
    "        try:\n",
    "            response = openrouter_client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a highly intelligent mental health professional tasked with identifying whether a given text exert from an individual shows signs of depression.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            result = response.choices[0].message.content\n",
    "            # print(result)  # test first\n",
    "            \n",
    "            # Try to extract rating and explanation\n",
    "            try:\n",
    "                # Assuming the response is formatted with a numerical rating followed by explanation\n",
    "                lines = result.strip().split('\\n')\n",
    "                rating_text = next((line for line in lines if any(str(i) in line for i in range(5))), '')\n",
    "                rating = next((int(i) for i in range(5) if str(i) in rating_text), None)\n",
    "                \n",
    "                # Get explanation (everything after the rating)\n",
    "                explanation = '\\n'.join(lines[lines.index(rating_text) + 1:]) if rating_text in lines else result\n",
    "                \n",
    "                result_df.at[idx, 'severity_rating'] = rating\n",
    "                result_df.at[idx, 'explanation'] = explanation.strip()\n",
    "            except:\n",
    "                # If parsing fails, store the full response in explanation\n",
    "                result_df.at[idx, 'severity_rating'] = None\n",
    "                result_df.at[idx, 'explanation'] = result\n",
    "                \n",
    "            # Only apply rate limiting for larger sample sizes\n",
    "            if num_samples > 20:\n",
    "                time.sleep(3)  # Rate limiting\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {idx}: {e}\")\n",
    "            result_df.at[idx, 'severity_rating'] = None\n",
    "            result_df.at[idx, 'explanation'] = f\"Error: {str(e)}\"\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extra_rows.csv already exists. Loading from file.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data/extra_rows.csv\"):\n",
    "    extra_rows = df[~df['text'].isin(test_df['text'])].head(20)\n",
    "    extra_rows.to_csv(\"data/extra_rows.csv\", index=False)\n",
    "else:\n",
    "    print(\"File extra_rows.csv already exists. Loading from file.\")\n",
    "    extra_rows = pd.read_csv(\"data/extra_rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File gemini_extra_rows.csv already exists. Loading from file.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data/gemini_extra_rows.csv\"):\n",
    "    extra_rows_gemini = get_depression_severity(extra_rows, num_samples=extra_rows.shape[0])\n",
    "    extra_rows_gemini.to_csv(\"data/gemini_extra_rows.csv\", index=False)\n",
    "else:\n",
    "    print(\"File gemini_extra_rows.csv already exists. Loading from file.\")\n",
    "    extra_rows_gemini = pd.read_csv(\"data/gemini_extra_rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File openrouter_extra_rows.csv already exists. Loading from file.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data/openrouter_extra_rows.csv\"):\n",
    "    extra_rows_openrouter = get_depression_severity_openrouter(extra_rows, num_samples=extra_rows.shape[0], model=\"deepseek/deepseek-chat:free\")\n",
    "    extra_rows_openrouter.to_csv(\"data/openrouter_extra_rows.csv\", index=False)\n",
    "else:\n",
    "    print(\"File openrouter_extra_rows.csv already exists. Loading from file.\")\n",
    "    extra_rows_openrouter = pd.read_csv(\"data/openrouter_extra_rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_results_openrouter.csv already exists. Loading from file.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data/test_results_openrouter.csv\"):\n",
    "    test_results_openrouter = get_depression_severity_openrouter(test_df, num_samples=test_df.shape[0], model=\"deepseek/deepseek-chat:free\")\n",
    "    test_results_openrouter.to_csv(\"data/test_results_openrouter.csv\", index=False)\n",
    "else:\n",
    "    print(\"File test_results_openrouter.csv already exists. Loading from file.\")\n",
    "    test_results_openrouter = pd.read_csv(\"data/test_results_openrouter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extra_rows_500.csv already exists. Loading from file.\n"
     ]
    }
   ],
   "source": [
    "# get 500 more samples from df without duplicates from test_df and extra_rows, split labels (0 and 1) equally\n",
    "if not os.path.exists(\"data/extra_rows_500.csv\"):\n",
    "    extra_rows_500 = df[~df['text'].isin(test_df['text']) & ~df['text'].isin(extra_rows['text'])].sample(n=500, random_state=42)\n",
    "    extra_rows_500.to_csv(\"data/extra_rows_500.csv\", index=False)\n",
    "else:\n",
    "    print(\"File extra_rows_500.csv already exists. Loading from file.\")\n",
    "    extra_rows_500 = pd.read_csv(\"data/extra_rows_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File gemini_extra_rows_500.csv already exists. Loading from file.\n"
     ]
    }
   ],
   "source": [
    "# gemini\n",
    "if not os.path.exists(\"data/gemini_extra_rows_500.csv\"):\n",
    "    extra_rows_gemini_500 = get_depression_severity(extra_rows_500, num_samples=extra_rows_500.shape[0])\n",
    "    extra_rows_gemini_500.to_csv(\"data/gemini_extra_rows_500.csv\", index=False)\n",
    "else:\n",
    "    print(\"File gemini_extra_rows_500.csv already exists. Loading from file.\")\n",
    "    extra_rows_gemini_500 = pd.read_csv(\"data/gemini_extra_rows_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = pd.read_csv(\"data/missing_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File remaining_missing_df_deepseek.csv already exists. Loading from file.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data/remaining_missing_df_deepseek.csv\"):\n",
    "    remaining = get_depression_severity_openrouter(missing_df, num_samples=missing_df.shape[0], model=\"deepseek/deepseek-chat\")\n",
    "    remaining.to_csv(\"data/remaining_missing_df_deepseek.csv\", index=False)\n",
    "else:\n",
    "    print(\"File remaining_missing_df_deepseek.csv already exists. Loading from file.\")\n",
    "    remaining = pd.read_csv(\"data/remaining_missing_df_deepseek.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_500 = pd.read_csv(\"data/gemini_extra_rows_500.csv\")\n",
    "gemini_25 = pd.read_csv(\"data/gemini-flash-2.0_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_525 = pd.concat([gemini_500, gemini_25], ignore_index=True)\n",
    "gemini_525.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/gemini-flash-2.0_results-525.csv\"):\n",
    "    gemini_525.to_csv(\"data/gemini-flash-2.0_results-525.csv\", index=False)\n",
    "else:\n",
    "    print(\"File gemini-flash-2.0_results-525.csv already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create llama_525_untrained based on gemini_525, dropping the columns that won't be used\n",
    "llama_525_untrained = gemini_525[['text', 'label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File llama-3.3-70B_results-525.csv already exists. Loading from file.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data/llama-3.3-70B_results-525.csv\"):\n",
    "    llama_525 = get_depression_severity_openrouter(llama_525_untrained, num_samples=llama_525_untrained.shape[0], model=\"meta-llama/llama-3.3-70b-instruct\")\n",
    "    llama_525.to_csv(\"data/llama-3.3-70B_results-525.csv\", index=False)\n",
    "else:\n",
    "    print(\"File llama-3.3-70B_results-525.csv already exists. Loading from file.\")\n",
    "    llama_525 = pd.read_csv(\"data/llama-3.3-70B_results-525.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/gemini-flash-2.0_results.csv already exists. Skipping.\n",
      "File data/deepseek-v3_results.csv already exists. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "gemini_output_path = \"data/gemini-flash-2.0_results.csv\"\n",
    "deepseek_output_path = \"data/deepseek-v3_results.csv\"\n",
    "\n",
    "# Check if test_results.csv exists\n",
    "if not os.path.exists(\"data/test_results.csv\"):\n",
    "    print(\"File test_results.csv not found. Please run the previous cells to generate this file.\")\n",
    "else:\n",
    "    test_results = pd.read_csv(\"data/test_results.csv\")\n",
    "    \n",
    "    # Process and save Gemini results\n",
    "    if not os.path.exists(gemini_output_path):\n",
    "        # Combine gemini_extra_rows and test_results into one dataframe\n",
    "        df_gemini_f2 = pd.concat([extra_rows_gemini, test_results], ignore_index=True)\n",
    "        df_gemini_f2.to_csv(gemini_output_path, index=False)\n",
    "        print(f\"Saved Gemini results to {gemini_output_path}\")\n",
    "    else:\n",
    "        print(f\"File {gemini_output_path} already exists. Skipping.\")\n",
    "        df_gemini_f2 = pd.read_csv(gemini_output_path)\n",
    "    \n",
    "    # Process and save DeepSeek results\n",
    "    if not os.path.exists(deepseek_output_path):\n",
    "        # Combine openrouter_extra_rows and test_results_openrouter into one dataframe\n",
    "        df_deepseek_v3 = pd.concat([extra_rows_openrouter, test_results_openrouter], ignore_index=True)\n",
    "        df_deepseek_v3.to_csv(deepseek_output_path, index=False)\n",
    "        print(f\"Saved DeepSeek results to {deepseek_output_path}\")\n",
    "    else:\n",
    "        print(f\"File {deepseek_output_path} already exists. Skipping.\")\n",
    "        df_deepseek_v3 = pd.read_csv(deepseek_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/untrained_525.csv\"):\n",
    "    untrained_525 = gemini_525[['text', 'label']].copy()\n",
    "    untrained_525.to_csv(\"data/untrained_525.csv\", index=False)\n",
    "else:\n",
    "    print(\"File untrained_525.csv already exists.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
